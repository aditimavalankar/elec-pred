{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from random import shuffle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy.special import betaln\n",
    "from prettytable import PrettyTable\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('dataset_1.csv', 'r')\n",
    "contents = f.read().split('\\r\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = contents[0].split(',')\n",
    "member_details = {}\n",
    "\n",
    "for i in xrange(1, len(contents)):\n",
    "    line = contents[i].split(',')\n",
    "    if len(line) != len(headers):\n",
    "        continue\n",
    "    member_details[line[0]] = {}\n",
    "    for j in xrange(1, len(headers)):\n",
    "        member_details[line[0]][headers[j]] = line[j].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the graph\n",
    "\n",
    "We create a graph analogous to the user-item graph, with members corresponding to users and topics corresponding to items. \n",
    "\n",
    "##### Step 1\n",
    "Map member names to user ids.\n",
    "\n",
    "##### Step 2\n",
    "Map topic names to item ids.\n",
    "\n",
    "##### Step 3\n",
    "Create links between users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userids = {}\n",
    "itemids = {}\n",
    "all_topics = set([])\n",
    "\n",
    "user_count = 0\n",
    "item_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for member in member_details:\n",
    "    user_count += 1\n",
    "    userids[member] = 'u' + str(user_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for member in member_details:\n",
    "    member_details[member]['Topics'] = member_details[member]['Topics'].split(';')\n",
    "    for t in member_details[member]['Topics']:\n",
    "        if t == '':\n",
    "            continue\n",
    "        all_topics.add(t)\n",
    "        \n",
    "for t in all_topics:\n",
    "    item_count += 1\n",
    "    itemids[t] = 'i' + str(item_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = {}\n",
    "\n",
    "for u in xrange(user_count):\n",
    "    graph['u' + str(u + 1)] = []\n",
    "    \n",
    "for i in xrange(item_count):\n",
    "    graph['i' + str(i + 1)] = []\n",
    "    \n",
    "for u in member_details:\n",
    "    for i in member_details[u]['Topics']:\n",
    "        if i == '':\n",
    "            continue\n",
    "        graph[userids[u]].append(itemids[i])\n",
    "        graph[itemids[i]].append(userids[u])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the graph\n",
    "\n",
    "We now clean the graph i.e. remove all nodes that are totally disconnected. We will not, for now, attempt the cold start problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing nodes ['u90', 'u92', 'u69', 'u61', 'u64', 'u65', 'u67', 'u25', 'u54', 'u124', 'u122', 'u123', 'u42', 'u41', 'u44', 'u139', 'u131', 'u109', 'u102', 'u100', 'u107', 'u104', 'u105', 'u23', 'u114', 'u116', 'u110', 'u119', 'u18', 'u14', 'u17', 'u80', 'u89', 'u160', 'u161', 'u162', 'u165', 'u168', 'u169', 'u170', 'u147', 'u153', 'u157', 'u156', 'u9', 'u4', 'u6', 'u76']\n"
     ]
    }
   ],
   "source": [
    "deleted_nodes = []\n",
    "\n",
    "for node in graph:\n",
    "    if len(graph[node]) == 0:\n",
    "        deleted_nodes.append(node)\n",
    "        \n",
    "print 'Removing nodes',\n",
    "print deleted_nodes\n",
    "\n",
    "for node in deleted_nodes:\n",
    "    del(graph[node])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and test sets (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = defaultdict(list)\n",
    "test = defaultdict(list)\n",
    "\n",
    "for node in graph:\n",
    "    if 'u' in node:\n",
    "        test[node] = []\n",
    "        n = len(graph[node])\n",
    "        indices = [x for x in xrange(n)]\n",
    "        shuffle(indices)\n",
    "        removed_items = []\n",
    "        for i in xrange((4*n)/5):\n",
    "            training[node].append(graph[node][indices[i]])\n",
    "            training[graph[node][indices[i]]].append(node)\n",
    "        for i in xrange((4*n)/5, n):\n",
    "            test[node].append(graph[node][indices[i]])\n",
    "            test[graph[node][indices[i]]].append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Verifying if the split has been done correctly or not.\n",
    "\n",
    "mismatches = 0\n",
    "\n",
    "for node in training:\n",
    "    if 'i' in node:\n",
    "        continue\n",
    "    if len(training[node]) + len(test[node]) != len(graph[node]):\n",
    "        mismatches += 1\n",
    "        \n",
    "print mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-rating map\n",
    "\n",
    "[No. of users who used item, No. of users who did not use item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users = 0\n",
    "item_rating_map = {}\n",
    "\n",
    "for node in training:\n",
    "    if 'u' in node:\n",
    "        num_users += 1\n",
    "\n",
    "for node in training:\n",
    "    if 'i' in node:\n",
    "        item_rating_map[node] = [len(training[node]), num_users - len(training[node])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PIS(item_pair):\n",
    "    item1 = item_pair[0]\n",
    "    item2 = item_pair[1]\n",
    "    total = 0\n",
    "    for i in range(0,item_rating_map[item2][0]):\n",
    "        total += np.exp(betaln(item_rating_map[item1][0]+i,item_rating_map[item1][1]+item_rating_map[item2][1]) -\\\n",
    "                        np.log(item_rating_map[item2][1]+i) - \\\n",
    "                        betaln(1+i, item_rating_map[item2][1]) -\\\n",
    "                        betaln(item_rating_map[item1][0],item_rating_map[item1][1])\n",
    "                       )\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PPS(item_pair):\n",
    "    item1 = item_pair[0]\n",
    "    item2 = item_pair[1]\n",
    "    p1 = (item_rating_map[item1][0] + 1) * 1.0 / (item_rating_map[item1][0] + item_rating_map[item1][1] + 1)\n",
    "    p2 = (item_rating_map[item2][0] + 1) * 1.0 / (item_rating_map[item2][0] + item_rating_map[item2][1] + 1)\n",
    "    return p1 * p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PORS(item_pair):\n",
    "    item1 = item_pair[0]\n",
    "    item2 = item_pair[1]\n",
    "    o1 = (item_rating_map[item1][0] + 1) * 1.0 / (item_rating_map[item1][1] + 1)\n",
    "    o2 = (item_rating_map[item2][0] + 1) * 1.0 / (item_rating_map[item2][1] + 1)\n",
    "    return o2 / o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(graph, target_user):\n",
    "    PIS_values = defaultdict(float)\n",
    "    PPS_values = defaultdict(float)\n",
    "    PORS_values = defaultdict(float)\n",
    "    \n",
    "    score_PIS = defaultdict(float)\n",
    "    score_PPS = defaultdict(float)\n",
    "    score_PORS = defaultdict(float)\n",
    "    \n",
    "    for primary_item in graph[target_user]:\n",
    "        for secondary_user in graph[primary_item]:\n",
    "            if secondary_user == target_user:\n",
    "                continue\n",
    "            for secondary_item in graph[secondary_user]:\n",
    "                if secondary_item in graph[target_user]:\n",
    "                    continue\n",
    "                \n",
    "                if (primary_item, secondary_item) not in PIS_values:\n",
    "                    PIS_values[(primary_item, secondary_item)] = PIS((primary_item, secondary_item))\n",
    "                score_PIS[secondary_item] += PIS_values[(primary_item, secondary_item)]\n",
    "\n",
    "                if (primary_item, secondary_item) not in PPS_values:\n",
    "                    PPS_values[(primary_item, secondary_item)] = PPS((primary_item, secondary_item))\n",
    "                score_PPS[secondary_item] += PPS_values[(primary_item, secondary_item)]\n",
    "                \n",
    "                if (primary_item, secondary_item) not in PORS_values:\n",
    "                    PORS_values[(primary_item, secondary_item)] = PORS((primary_item, secondary_item))\n",
    "                score_PORS[secondary_item] += PORS_values[(primary_item, secondary_item)]\n",
    "                \n",
    "    return score_PIS, score_PPS, score_PORS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_ranking_list(score_list): \n",
    "    ranking_list = {} \n",
    "\n",
    "    for user in score_list: \n",
    "        sorted_score = sorted(score_list[user].items(), key=operator.itemgetter(1), reverse=True)\n",
    "        ranking_list[user]= [item[0] for item in sorted_score]\n",
    "\n",
    "    return ranking_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  Users done\n",
      "2  Users done\n",
      "3  Users done\n",
      "4  Users done\n",
      "5  Users done\n",
      "6  Users done\n",
      "7  Users done\n",
      "8  Users done\n",
      "9  Users done\n",
      "10  Users done\n",
      "11  Users done\n",
      "12  Users done\n",
      "13  Users done\n",
      "14  Users done\n",
      "15  Users done\n",
      "16  Users done\n",
      "17  Users done\n",
      "18  Users done\n",
      "19  Users done\n",
      "20  Users done\n",
      "21  Users done\n",
      "22  Users done\n",
      "23  Users done\n",
      "24  Users done\n",
      "25  Users done\n",
      "26  Users done\n",
      "27  Users done\n",
      "28  Users done\n",
      "29  Users done\n",
      "30  Users done\n",
      "31  Users done\n",
      "32  Users done\n",
      "33  Users done\n",
      "34  Users done\n",
      "35  Users done\n",
      "36  Users done\n",
      "37  Users done\n",
      "38  Users done\n",
      "39  Users done\n",
      "40  Users done\n",
      "41  Users done\n",
      "42  Users done\n",
      "43  Users done\n",
      "44  Users done\n",
      "45  Users done\n",
      "46  Users done\n",
      "47  Users done\n",
      "48  Users done\n",
      "49  Users done\n",
      "50  Users done\n",
      "51  Users done\n",
      "52  Users done\n",
      "53  Users done\n",
      "54  Users done\n",
      "55  Users done\n",
      "56  Users done\n",
      "57  Users done\n",
      "58  Users done\n",
      "59  Users done\n",
      "60  Users done\n",
      "61  Users done\n",
      "62  Users done\n",
      "63  Users done\n",
      "64  Users done\n",
      "65  Users done\n",
      "66  Users done\n",
      "67  Users done\n",
      "68  Users done\n",
      "69  Users done\n",
      "70  Users done\n",
      "71  Users done\n",
      "72  Users done\n",
      "73  Users done\n",
      "74  Users done\n",
      "75  Users done\n",
      "76  Users done\n",
      "77  Users done\n",
      "78  Users done\n",
      "79  Users done\n",
      "80  Users done\n",
      "81  Users done\n",
      "82  Users done\n",
      "83  Users done\n",
      "84  Users done\n",
      "85  Users done\n",
      "86  Users done\n",
      "87  Users done\n",
      "88  Users done\n",
      "89  Users done\n",
      "90  Users done\n",
      "91  Users done\n",
      "92  Users done\n",
      "93  Users done\n",
      "94  Users done\n",
      "95  Users done\n",
      "96  Users done\n",
      "97  Users done\n",
      "98  Users done\n",
      "99  Users done\n",
      "100  Users done\n",
      "101  Users done\n",
      "102  Users done\n",
      "103  Users done\n",
      "104  Users done\n",
      "105  Users done\n",
      "106  Users done\n",
      "107  Users done\n",
      "108  Users done\n",
      "109  Users done\n",
      "110  Users done\n",
      "111  Users done\n",
      "112  Users done\n",
      "113  Users done\n",
      "114  Users done\n",
      "115  Users done\n",
      "116  Users done\n",
      "117  Users done\n",
      "118  Users done\n",
      "119  Users done\n"
     ]
    }
   ],
   "source": [
    "score_PIS = {} \n",
    "score_PPS = {} \n",
    "score_PORS = {}\n",
    "\n",
    "count = 0\n",
    "for user in training:\n",
    "    if user[0] == 'u':\n",
    "        score_PIS[user], score_PPS[user], score_PORS[user] = score(training, user)\n",
    "        count += 1\n",
    "        if count%1==0:\n",
    "            print count,' Users done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_PIS = generate_ranking_list(score_PIS)\n",
    "ranking_PPS = generate_ranking_list(score_PPS)\n",
    "ranking_PORS = generate_ranking_list(score_PORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_at_k(k, predictions, lp):\n",
    "    patk = 0.0\n",
    "    for user in predictions:\n",
    "        correct = 0\n",
    "        for i in range(k):\n",
    "            if i >= len(predictions[user]):\n",
    "                break\n",
    "            if predictions[user][i] in lp[user]:\n",
    "                correct+=1\n",
    "        patk += 1.0*correct/k\n",
    "    return patk/len(predictions.keys())\n",
    "\n",
    "def MAP(predictions, lp):\n",
    "    MAP = 0.0\n",
    "    for user in predictions:\n",
    "        umap = 0.0\n",
    "        correct = 0\n",
    "        for i in range(len(predictions[user])):\n",
    "            if predictions[user][i] in lp[user]:\n",
    "                correct += 1\n",
    "                umap += 1.0*correct/(i+1)\n",
    "        MAP += umap/max(1,len(lp[user]))\n",
    "    return MAP/len(predictions.keys())\n",
    "\n",
    "def MRR(predictions, lp):\n",
    "    MRR = 0.0\n",
    "    for user in predictions:\n",
    "        for i in range(len(predictions[user])):\n",
    "            if predictions[user][i] in lp[user]:\n",
    "                MRR += 1.0/(i+1)\n",
    "                break\n",
    "    return MRR/len(predictions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lp(predictions):\n",
    "    lp = {}\n",
    "    for user in predictions:\n",
    "        lp[user] = test[user]\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'MAP':defaultdict(float), 'MRR':defaultdict(float), 'P@5':defaultdict(float), 'P@10':defaultdict(float)}\n",
    "t = PrettyTable(['Method', 'MAP', 'MRR', 'P@5', 'P@10'])\n",
    "\n",
    "predictions = ranking_PIS\n",
    "lp = get_lp(predictions)\n",
    "scores['MAP']['PIS'] = MAP(predictions, lp)\n",
    "scores['MRR']['PIS'] = MRR(predictions, lp)\n",
    "scores['P@5']['PIS'] = p_at_k(5, predictions, lp)\n",
    "scores['P@10']['PIS'] = p_at_k(10, predictions, lp)\n",
    "t.add_row(['PIS', scores['MAP']['PIS'], scores['MRR']['PIS'], scores['P@5']['PIS'], scores['P@10']['PIS']])\n",
    "\n",
    "predictions = ranking_PPS\n",
    "lp = get_lp(predictions)\n",
    "scores['MAP']['PPS'] = MAP(predictions, lp)\n",
    "scores['MRR']['PPS'] = MRR(predictions, lp)\n",
    "scores['P@5']['PPS'] = p_at_k(5, predictions, lp)\n",
    "scores['P@10']['PPS'] = p_at_k(10, predictions, lp)\n",
    "t.add_row(['PPS', scores['MAP']['PPS'], scores['MRR']['PPS'], scores['P@5']['PPS'], scores['P@10']['PPS']])\n",
    "\n",
    "predictions = ranking_PORS\n",
    "lp = get_lp(predictions)\n",
    "scores['MAP']['PORS'] = MAP(predictions, lp)\n",
    "scores['MRR']['PORS'] = MRR(predictions, lp)\n",
    "scores['P@5']['PORS'] = p_at_k(5, predictions, lp)\n",
    "scores['P@10']['PORS'] = p_at_k(10, predictions, lp)\n",
    "t.add_row(['PORS', scores['MAP']['PORS'], scores['MRR']['PORS'], scores['P@5']['PORS'], scores['P@10']['PORS']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------------+----------------+----------------+\n",
      "| Method |      MAP       |      MRR       |      P@5       |      P@10      |\n",
      "+--------+----------------+----------------+----------------+----------------+\n",
      "|  PIS   | 0.114851291852 | 0.34633438032  | 0.188235294118 | 0.172268907563 |\n",
      "|  PPS   | 0.107095040271 | 0.328939040055 | 0.181512605042 | 0.16974789916  |\n",
      "|  PORS  | 0.115401321668 | 0.351382351978 | 0.18487394958  | 0.176470588235 |\n",
      "+--------+----------------+----------------+----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
